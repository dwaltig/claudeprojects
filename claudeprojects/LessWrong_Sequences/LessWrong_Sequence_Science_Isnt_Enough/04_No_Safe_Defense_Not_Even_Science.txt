No Safe Defense, Not Even Science
Eliezer Yudkowsky

Of the people I know who are reaching upward as rationalists, there is a surprising tendency to hear things like: "My family joined a cult and I had to break out," or "One of my parents was clinically insane and I had to learn to filter out reality from their madness." My own experience with growing up in an Orthodox Jewish family seems tame by comparison... but it accomplished the same outcome: It broke my core emotional trust in the sanity of the people around me.

Until this core emotional trust is broken, you don't start growing as a rationalist. Maybe any unusual skills you acquire—anything that makes you unusually rational—requires you zig when other people zag. Maybe that's just too scary, if the world still seems like a sane place unto you. Or maybe you don't bother putting in the hard work to be extra bonus sane, if normality doesn't scare the hell out of you.

People who've had their trust broken in the sanity of the people around them seem to be able to evaluate strange ideas on their merits, without feeling nervous about their strangeness. True dissent doesn't feel like going to school wearing black; it feels like going to school wearing a clown suit. I've never seen anyone begin to grow as a rationalist until they make a deep emotional break with the wisdom of their pack.

Once upon a time, there was something I trusted. Eliezer18 trusted Science. He dutifully acknowledged that the social process of science was flawed. But who could possibly be foolish enough to question, "The experimental method shall decide which hypothesis wins"? Part of what fooled Eliezer18 was an aversion to ideas that resembled things idiots had said. People who questioned the ideal of Science were invariably trying to sell you snake oil, or trying to safeguard their favorite form of stupidity.

If there'd been any other ideal that was a few centuries old, the young Eliezer would have looked at it and said, "I wonder if this is really right, and whether there's a way to do better." But not the ideal of Science. Science was the master idea, the idea that let you change ideas.

When Eliezer23 realized exactly how stupid the stupid theory had been—and that Traditional Rationality had not saved him from it—and that Science would have been perfectly okay with his wasting ten years testing the stupid idea, so long as afterward he admitted it was wrong... it simply became obvious that I'd been stupid.

That's the trust I'm trying to break in you. You are not safe. Ever. Not even Science can save you. The ideals of Science were born centuries ago, in a time when no one knew anything about probability theory or cognitive biases. Science demands too little of you, it blesses your good intentions too easily, it is not strict enough. Don't think that if you only follow the rules of Science, that makes your reasoning defensible.

There is no known procedure you can follow that makes your reasoning defensible. No, not even if you turn to Bayescraft. It's much harder to use and you'll never be sure that you're doing it right. The discipline of Bayescraft is younger by far than the discipline of Science. You will find no textbooks, no elderly mentors. You don't know what your own mind is really doing. They find a new cognitive bias every week. The formal math is impossible to apply.

One of the problems with Science is that it's too vague to really scare you. "Ideas should be tested by experiment." How can you go wrong with that?

Your trust will not break, until you apply all that you have learned here and from other books, and take it as far as you can go, and find that this too fails you—that you have still been a fool, and no one warned you against it. To take sole responsibility, to live without any trustworthy defenses, and to forge a higher Art than the one you were once taught. No one begins to truly search for the Way until their parents have failed them, their gods are dead, and their tools have shattered in their hand.

Post Scriptum: On reviewing a draft of this essay, I discovered a fairly inexcusable flaw in reasoning. I am leaving it in. Just in case you thought that taking my advice made you safe; or that you were supposed to look for flaws, but not find any. It is living with uncertainty—knowing on a gut level that there are flaws, they are serious and you have not found them—that is the difficult thing.
